{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XcCHeYYyapv3"
   },
   "outputs": [],
   "source": [
    "# check whether GPU is provided\n",
    "!nvcc --version\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8y_2L4Yg9Lnr"
   },
   "outputs": [],
   "source": [
    "# %cd ..\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"paultimothymooney/chest-xray-pneumonia\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jbvV5GPC9olU"
   },
   "outputs": [],
   "source": [
    "!cp /content/gdrive/MyDrive/datasets/chest_xray.zip ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2SzyCf0Zn9Cf"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "local_zip = 'chest_xray.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('data/')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1BxhK1wTiFBu"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "base_dir = 'data/'\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'test')\n",
    "# test_dir = os.path.join(base_dir, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N8PP7lcrgGnq"
   },
   "source": [
    "**Building our network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FopSstCWeq0A"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(150, 150, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JFEiOv8Zgj7Y"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E9cP0Je9glDf"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(learning_rate=1e-4),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1wziOiSgtiU"
   },
   "source": [
    "**Data preprocessing**\n",
    "\n",
    "Devemos converter os dados em tensores de ponto flutuante. Devemos seguir as seguintes etapas:\n",
    "\n",
    "Leia os arquivos de imagem.\n",
    "Decodifique em pixels RGB\n",
    "Converta-os em tensores de ponto flutuante.\n",
    "Rescale de cada pixels de (0 a 255) para [0, 1]\n",
    "\n",
    "O keras.preprocessing.image contém a classe ImageDataGenerator, que permite configurar geradores Python que podem transformar automaticamente arquivos de imagem em disco em lotes de tensores pré-processados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wXYUCmOcgnDY"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# All images will be rescaled by 1./255\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        train_dir,\n",
    "        # All images will be resized to 150x150\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='sparse')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=12,\n",
    "        class_mode='sparse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-8GgSWGQKf7r"
   },
   "source": [
    "Vamos dar uma olhada no formato dos arquivos gerados pelo python\n",
    "\n",
    "Foram produzidos batches de imagens RGB de 150x150 (shape (20, 150, 150, 3)) e labels binárias (shape (20,))\n",
    "\n",
    "20 é o número de amostras em cada batch (o tamanho do batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wccSRTyNi9GJ"
   },
   "outputs": [],
   "source": [
    "for data_batch, labels_batch in train_generator:\n",
    "    print('data batch shape:', data_batch.shape)\n",
    "    print('labels batch shape:', labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ob2YuvNVLPeX"
   },
   "source": [
    "**Treinando o modelo**\n",
    "\n",
    "Vamos ajustar nosso modelo aos dados usando o gerador, usando o método **fit_generator**\n",
    "\n",
    "train_generator: (primeiro argumento) produzirá batches indefinidamente.\n",
    "\n",
    "Como os dados estão sendo gerados infinitamente, o gerador precisa saber por exemplo quantas amostras extrair do gerador antes de declarar uma época.\n",
    "\n",
    "Assim, usamos o **steps_per_epoch** para que, depois de extrair \"steps_per_epoch\" batches do gerador, o model.fit irá para a próxima época. Neste caso, cada batch possui 20 amostras, portanto, serão necesssário 100 batches até atingirmos o objetivo de 2000 amostras.\n",
    "\n",
    "**validation_data**: pode ser um gerador (como neste caso) e portanto, temos que fornecer o argumento **validation_steps** pois o gerador irá gerar dados infinitamente. O argumento validation_steps determina quantos batches serão extraídos do gerador Python de validação para a avaliação do modelo (50 pois nosso conjunto de validação possui 1000 amostras).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XkRFxkHhjPZW"
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=50,\n",
    "      epochs=10,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NiAlEpNHjw_I"
   },
   "outputs": [],
   "source": [
    "model.save('chest_xray.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F2aiwWLYj16K"
   },
   "source": [
    "Vamos plotar a loss e a acurácia do modelo sobre os dados de treinamento e validação durante o treinamento:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j2zzKgwhj2ZR"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4FPGbsB1QUNq"
   },
   "source": [
    "Observe que a acurácia dos dados de treinamento aumenta linearmente ao longo do tempo até atingir quase 100% (e validação não passa de 70%).\n",
    "\n",
    "A validation loss atinge seu mínimo depois de apenas cinco épocas, e a train loss continua diminuindo linearmente até atingir quase 0.\n",
    "\n",
    "Como temos apenas poucas amostras de treinamento (2000), o maior risco é de overfitting (poderíamos resolver o problema com dropout).\n",
    "\n",
    "No entanto, usaremos uma técnica muito como para visão computacional que pode solucionar o problema de overfitting: **data augmentation**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8NHVVxcYRyQH"
   },
   "source": [
    "Mas, antes de abordarmos o assunto de data augmentation, vamos aprender a realizar algumas poredições no nosso modelo treinado.\n",
    "\n",
    "**Realizando Predições**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xC1mo05bSDsc"
   },
   "source": [
    "Obtendo uma imagem de exemplo usando no treinamento (veja que esta imagem já está pré-processada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pbVcfetnnHgH"
   },
   "outputs": [],
   "source": [
    "data_batch, labels_batch = validation_generator[0]\n",
    "print('data batch shape:', data_batch.shape)\n",
    "print(data_batch[5].shape)\n",
    "\n",
    "x = data_batch[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OkM9QWryVWRp"
   },
   "source": [
    "Observe o shape da imagem (150, 150, 3), para a predição temos que converter para um tensor 4D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "50YbCvezmiOO"
   },
   "outputs": [],
   "source": [
    "x = x.reshape(1, 150, 150, 3)\n",
    "\n",
    "print (x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59XlvqiLoN2v"
   },
   "source": [
    "Realizando a inferência: a loss function binary_crossentropy retorna um valor de probabilidade entre 0 e 1 para a classificação binária (cat - 0 e dog - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Eug5ibhoM7w"
   },
   "outputs": [],
   "source": [
    "prob = model.predict(x)\n",
    "\n",
    "# print(prob)\n",
    "\n",
    "print(np.around(model.predict(x), 2))\n",
    "\n",
    "preds = np.argmax(model.predict(x), axis=-1)\n",
    "\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WbdCqR8NuaWG"
   },
   "source": [
    "Código usado na produção\n",
    "\n",
    "Abrindo uma imagem diretamente do diretório. Obsserve que agora a imagem não está pre-processada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xqi5B3cwum0g"
   },
   "outputs": [],
   "source": [
    "from google.colab.patches import cv2_imshow\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# path = os.path.join(base_dir, 'validation/dogs/dog.2027.jpg')\n",
    "path = os.path.join(base_dir, 'test/PNEUMONIA/person109_bacteria_528.jpeg')\n",
    "\n",
    "img = cv2.imread(path)\n",
    "cv2_imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rdbUCJxTveOh"
   },
   "outputs": [],
   "source": [
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "erhEMHoiVtUc"
   },
   "source": [
    "Vamos carregar a imagem usando PIL (biblioteca para processamento de imagens em Python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aIBoU5wYwSN9"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from PIL import Image\n",
    "\n",
    "img = load_img(path, target_size=(150, 150))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8tmphD7UV2k_"
   },
   "source": [
    "Rescale de cada pixels de (0 a 255) para [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bFQObhcnCe83"
   },
   "outputs": [],
   "source": [
    "from numpy import asarray\n",
    "\n",
    "img = asarray(img)\n",
    "\n",
    "print('Data Type: %s' % img.dtype)\n",
    "print('Min: %.3f, Max: %.3f' % (img.min(), img.max()))\n",
    "\n",
    "img = img.astype('float32')\n",
    "img /= 255.0\n",
    "\n",
    "print('Min: %.3f, Max: %.3f' % (img.min(), img.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rOFMH9UYCyk7"
   },
   "outputs": [],
   "source": [
    "x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
    "x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
    "\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KDTtT8qUBU3t"
   },
   "outputs": [],
   "source": [
    "prob = model.predict(x)\n",
    "\n",
    "preds = np.argmax(model.predict(x), axis=-1)\n",
    "\n",
    "print(prob, preds)\n",
    "\n",
    "print(np.around(model.predict(x), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDjAJjno_Y7S"
   },
   "source": [
    "**Usando data augmentation**\n",
    "\n",
    "O problema de overfitting foi causado por ter poucas amostras para aprender, ou seja, faz com que o modelo seja incapazes de generalizar para novos dados.\n",
    "\n",
    "Data augmentation gera mais dados de treinamento a partir de amostras existentes de treinamento, por meio de várias transformações aleatórias que produzem novas imagens.\n",
    "\n",
    "O objetivo é que, durante o treinamento, nosso modelo nunca veja exatamente a mesma imagem duas vezes. Isso ajuda o modelo a se expor a mais aspectos dos dados e a generalizar melhor.\n",
    "\n",
    "Você pude utilizar operações de processamento de imagens comuns para produzir novas amostras de dados a partir das imagens de treinamento.\n",
    "\n",
    "Acesse para exemplos:\n",
    "\n",
    "https://github.com/albumentations-team/albumentations\n",
    "\n",
    "https://github.com/codebox/image_augmentor\n",
    "\n",
    "\n",
    "No Keras, isso pode ser feito configurando várias transformações aleatórias a serem executadas nas imagens lidas pela nossa instância do ImageDataGenerator.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QODDjYgi_b95"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "      # rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PmfIYy6oEvpN"
   },
   "source": [
    "Estas são apenas algumas das opções disponíveis (para mais, consulte a documentação do Keras).\n",
    "\n",
    "rotation_range é um valor em graus (0-180), um intervalo no qual gira aleatoriamente as imagens.\n",
    "\n",
    "width_shift e height_shift são intervalos dentro dos quais rotaciona aleatoriamente imagens na vertical ou na horizontal.\n",
    "\n",
    "shear_range é para aplicar aleatoriamente transformações de cisalhamento.\n",
    "\n",
    "zoom_range é para ampliar aleatoriamente as imagens.\n",
    "\n",
    "horizontal_flip é para virar aleatoriamente metade das imagens horizontalmente\n",
    "\n",
    "fill_mode é a estratégia usada para preencher pixels recém-criados, que podem aparecer após uma rotação ou uma mudança de largura / altura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bgvb0ZwUFcau"
   },
   "outputs": [],
   "source": [
    "# Directory with our training cat pictures\n",
    "train_NORMAL_dir = os.path.join(train_dir, 'NORMAL')\n",
    "\n",
    "# Directory with our training dog pictures\n",
    "train_PNEUMONIA_dir = os.path.join(train_dir, 'PNEUMONIA')\n",
    "\n",
    "\n",
    "# Directory with our validation cat pictures\n",
    "validation_NORMAL_dir = os.path.join(validation_dir, 'NORMAL')\n",
    "\n",
    "# Directory with our validation dog pictures\n",
    "validation_PNEUMONIA_dir = os.path.join(validation_dir, 'PNEUMONIA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I8yKbIT_E18q"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "fnames = [os.path.join(train_NORMAL_dir, fname) for fname in os.listdir(train_NORMAL_dir)]\n",
    "\n",
    "# We pick one image to \"augment\"\n",
    "img_path = fnames[3]\n",
    "\n",
    "# Read the image and resize it\n",
    "img = image.load_img(img_path, target_size=(150, 150))\n",
    "\n",
    "# Convert it to a Numpy array with shape (150, 150, 3)\n",
    "x = image.img_to_array(img)\n",
    "\n",
    "# Reshape it to (1, 150, 150, 3)\n",
    "x = x.reshape((1,) + x.shape)\n",
    "\n",
    "# The .flow() command below generates batches of randomly transformed images.\n",
    "# It will loop indefinitely, so we need to `break` the loop at some point!\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1):\n",
    "    plt.figure(i)\n",
    "    imgplot = plt.imshow(image.array_to_img(batch[0]))\n",
    "    i += 1\n",
    "    if i % 4 == 0:\n",
    "        break\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aufXBAbDZqrW"
   },
   "source": [
    "Se treinarmos uma nova rede usando data augmentation, a rede nunca verá duas vezes a mesma entrada. No entanto, isso pode não ser suficiente para se livrar completamente do problema de overfitting. Para isso, também adicionaremos uma camada Dropout ao modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_rmrQJ7uGYg7"
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(150, 150, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(4, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(learning_rate=1e-4),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HKVi74nAGeSO"
   },
   "source": [
    "Treinando o modelo usando data augmentation e dropout\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZBpqpt3UGfDN"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,)\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        train_dir,\n",
    "        # All images will be resized to 150x150\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='sparse')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=12,\n",
    "        class_mode='sparse')\n",
    "\n",
    "history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=50,\n",
    "      epochs=10,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z7RV09C_G2n5"
   },
   "outputs": [],
   "source": [
    "model.save('chest_xray_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eilFzqctG4AE"
   },
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qr7cGIIjaWZ_"
   },
   "source": [
    "Observe que agora não estamos mais enfrentando o problema de overfitting.\n",
    "\n",
    "As curvas de treinamento estão acompanhando de perto as curvas de validação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UKAiEu9aaujk"
   },
   "source": [
    "Referência: François Chollet. Deep Learning with Python. November 2017"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
